{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellbell\n",
    "%pylab inline\n",
    "import csv\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputValues = np.zeros(3)\n",
    "inputValues = np.zeros(12)\n",
    "\n",
    "recIndex = 0\n",
    "isRecording = False\n",
    "modelIsTrained = False\n",
    "\n",
    "### gestures\n",
    "gestures = np.zeros(10, dtype=np.object)\n",
    "newGesture = np.zeros(0)\n",
    "\n",
    "# print( shape(gestures ) )\n",
    "\n",
    "params = {'N':250, 'NetSR':1.5, 'NetinpScaling':1.3,'BiasScaling':0.9,\n",
    "         'washoutLength':200, 'learnLength':1200, \n",
    "          'LR': 0.2, 'connIn': 0.2, 'Nin': 12\n",
    "#           'patts': gestures[[0,1,2,3]]\n",
    "#           'patts':gestures[[0,1,2,3]]\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "def save_gestures_to_file():\n",
    "    ts = str(datetime.datetime.timestamp(datetime.datetime.now()))\n",
    "    with open(r\"patterns_chrysalis_\" + ts + \".pickled\", \"wb\") as output_file:\n",
    "        pickle.dump(gestures, output_file, protocol=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateInternalWeights(nInternalUnits, connectivity):\n",
    "    success = False\n",
    "    internalWeights = 0\n",
    "    while success == False:\n",
    "        try:\n",
    "            internalWeights = np.random.randn(nInternalUnits,nInternalUnits) * (np.random.random((nInternalUnits,nInternalUnits)) < connectivity)\n",
    "            specRad = abs(np.linalg.eig(internalWeights)[0][0])\n",
    "            if (specRad > 0):\n",
    "                internalWeights = internalWeights / specRad\n",
    "                success = True\n",
    "        except e:\n",
    "            print(e)\n",
    "    return internalWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeClassifierNetwork(p):\n",
    "    Netconnectivity = 1\n",
    "    if p['N'] > 20:\n",
    "        Netconnectivity = 10.0/p['N'];\n",
    "    WstarRaw = generateInternalWeights(p['N'], Netconnectivity)\n",
    "    WinRaw = 2 * (np.random.rand(p['N'], p['Nin']) - 0.5) *  (np.random.random((p['N'],  p['Nin'])) < p['connIn'])\n",
    "    WbiasRaw = 2 * (np.random.rand(p['N'], 1) - 0.5)\n",
    "\n",
    "    #Scale raw weights     \n",
    "    Wstar = p['NetSR'] * WstarRaw;\n",
    "    W = Wstar\n",
    "    Win = p['NetinpScaling'] * WinRaw;\n",
    "    Wbias = p['BiasScaling'] * WbiasRaw;  \n",
    "    I = np.eye(p['N'])\n",
    "    xCollector = np.zeros((p['N'], p['learnLength']))\n",
    "    pCollector = np.zeros(( p['Nin'], p['learnLength']))\n",
    "    x = np.zeros((p['N'],1))\n",
    "    \n",
    "    allTrainxArgs = np.zeros((p['N'] + 1, 0));\n",
    "#     allTrainOldxArgs = np.zeros((p['N'], 0));\n",
    "#     allTrainWtargets = np.zeros((p['N'], 0));\n",
    "#     allTrainOuts = np.zeros(( p['Nin'], 0));\n",
    "    patternRs =  np.zeros((1, p['patts'].size), dtype=np.object)\n",
    "    \n",
    "    for i_pattern in range(p['patts'].size):\n",
    "        print('Observing pattern ', i_pattern)\n",
    "        patt = p['patts'][i_pattern]\n",
    "        xCollector = np.zeros((p['N'] + 1, p['learnLength']));\n",
    "#         xOldCollector = np.zeros((p['N'], p['learnLength']));\n",
    "#         WTargetCollector = np.zeros((p['N'], p['learnLength']));\n",
    "#         pCollector = np.zeros(( p['Nin'], p['learnLength']));\n",
    "        x = np.zeros((p['N'], 1));\n",
    "\n",
    "        for n in range(p['washoutLength'] + p['learnLength']):\n",
    "            u = patt.take(n, mode='wrap', axis=0)\n",
    "            xOld = x\n",
    "            Wtarget = (Wstar.dot(x)) + vstack(Win.dot(u))\n",
    "            x = ((1.0-p['LR']) * xOld) + (p['LR'] * tanh(Wtarget + Wbias))\n",
    "            if n >= p['washoutLength']:\n",
    "                xCollector[:, n - p['washoutLength']] = np.concatenate((x[:,0], np.array([1])))\n",
    "#                 xOldCollector[:, n - p['washoutLength']] = xOld[:,0]\n",
    "#                 WTargetCollector[:, n - p['washoutLength']] = Wtarget[:,0]\n",
    "#                 pCollector[:, n - p['washoutLength']] = u\n",
    "#             uOld = u\n",
    "        \n",
    "        R = xCollector[0:-1].dot(xCollector[0:-1].T) / p['learnLength']\n",
    "        patternRs[0,i_pattern] = R\n",
    "        allTrainxArgs = np.concatenate((allTrainxArgs, xCollector), axis=1)\n",
    "#         allTrainOldxArgs = np.concatenate((allTrainOldxArgs, xOldCollector), axis=1)\n",
    "#         allTrainOuts = np.concatenate((allTrainOuts, pCollector), axis=1)\n",
    "#         allTrainWtargets = np.concatenate((allTrainWtargets, WTargetCollector), axis=1)\n",
    "        print(\"Done\")\n",
    "\n",
    "    return locals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeConceptor(p, net, i_pattern, alpha):\n",
    "#     print('Computing conceptor, alpha: ', alpha)\n",
    "    Cs = np.zeros((4, 1), dtype=np.object)\n",
    "    R = net['patternRs'][0,i_pattern]\n",
    "    [U,s,V] = svd(R)\n",
    "    S = diag(s)\n",
    "    Snew = (S * linalg.inv(S + pow(alpha, -2) * np.eye(p['N'])))\n",
    "\n",
    "    C =  U.dot(Snew).dot(U.conj().T);\n",
    "    Cs[0,0] = C\n",
    "    Cs[1,0] = U\n",
    "    Cs[2,0] = diag(Snew)\n",
    "    Cs[3,0] = diag(S)\n",
    "\n",
    "    return Cs\n",
    "\n",
    "def testConceptor(net, cNet, recallTestLength):\n",
    "    trials = 1\n",
    "    attens = np.zeros(trials)\n",
    "    p = net['p']\n",
    "    C = cNet[0,0]\n",
    "    for i_trial in range(trials):\n",
    "        x_CTestPL = np.zeros((p['N'], recallTestLength))\n",
    "        z_CTestPL = np.zeros((p['N'], recallTestLength))\n",
    "#         p_CTestPL = np.zeros((1, recallTestLength))\n",
    "        x = 0.5 * np.random.randn(p['N'],1)\n",
    "        z = x\n",
    "        for n in range(recallTestLength + p['washoutLength']):\n",
    "            xOld = x\n",
    "            Wtarget = (net['W'].dot(x))\n",
    "            z = ((1.0-p['LR']) * xOld) + (p['LR'] * tanh(Wtarget + net['Wbias']))\n",
    "            x = C.dot(z)\n",
    "            xPrev = x\n",
    "            if (n > p['washoutLength']):\n",
    "                x_CTestPL[:,n-p['washoutLength']] = x.T\n",
    "                z_CTestPL[:,n-p['washoutLength']] = z.T\n",
    "#                 p_CTestPL[:,n-p['washoutLength']] = cNet['net']['Wout'].dot(np.concatenate((x[:,0], np.array([1]))))\n",
    "\n",
    "#         attenuation = np.mean(pow(np.sum(z_CTestPL[:,:] - x_CTestPL[:,:], axis=1),2)) / np.mean(pow(np.sum(z_CTestPL[:,:], axis=1),2))\n",
    "        attenuation = np.mean(pow(np.linalg.norm(z_CTestPL[:,:] - x_CTestPL[:,:], axis=1),2)) / np.mean(pow(np.linalg.norm(z_CTestPL[:,:], axis=1),2))\n",
    "        attens[i_trial] = attenuation\n",
    "        \n",
    "    return np.mean(attens)\n",
    "\n",
    "def fitnessf(aperture, *args):\n",
    "    print('Pattern: ', args[0])\n",
    "    cnet = computeConceptor(net['p'], net, args[0], aperture)\n",
    "    atten = testConceptor(net, cnet, 300)\n",
    "    return atten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "def calculate_apertures():\n",
    "    apertures = [sp.optimize.fminbound(fitnessf, 0, 500,  disp=3, xtol=1, args = (x,)) \n",
    "             for x in np.arange(net['p']['patts'].shape[0])]\n",
    "    return apertures\n",
    "\n",
    "def calculate_conceptors( apertures ):\n",
    "    #store conceptors with calculated apertures\n",
    "    patternCs = np.zeros(len(apertures), dtype=np.object)\n",
    "    for i_patt in range(patternCs.size):\n",
    "        patternCs[i_patt] = computeConceptor(net['p'], net, i_patt, apertures[i_patt])\n",
    "    cellbell.ding()\n",
    "    return patternCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as dist\n",
    "\n",
    "#calc negative evidence\n",
    "def conceptorOr(C,B):\n",
    "    I = np.eye(C.shape[0])\n",
    "    return linalg.inv(I + linalg.inv(C.dot(linalg.inv(1.0-C)) + B.dot(linalg.inv(1.0-B))))\n",
    "\n",
    "\n",
    "def plotConceptorPatterns(net, cNet, recallTestLength):\n",
    "    patternCsNeg = np.zeros(len(apertures), dtype=np.object)\n",
    "\n",
    "    for i_c in arange(net['p']['patts'].size):\n",
    "        idxs = np.delete(arange(net['p']['patts'].size), i_c)\n",
    "        Cneg = conceptorOr(patternCs[idxs[0]][0,0], patternCs[idxs[1]][0,0])\n",
    "        for i_idx in idxs[2:]:\n",
    "            Cneg = conceptorOr(Cneg, patternCs[i_idx][0,0])\n",
    "        Cneg = 1.0 - Cneg\n",
    "        patternCsNeg[i_c] = Cneg\n",
    "\n",
    "#     x_CTestPL = np.zeros((3, recallTestLength, p['patts'].size))\n",
    "#     p_CTestPL = np.zeros((1, recallTestLength, p['patts'].size))\n",
    "    cx_CTestPL = np.zeros((net['p']['patts'].size+1,recallTestLength))\n",
    "    pat_CTestPL = np.zeros((net['p']['Nin'],recallTestLength))\n",
    "    \n",
    "    CNone = conceptorOr(patternCs[0][0,0], patternCs[1][0,0])\n",
    "    for i_idx in arange(net['p']['patts'].size)[2:]:\n",
    "        CNone = conceptorOr(CNone, patternCs[i_idx][0,0])\n",
    "    CNone = 1.0 - CNone\n",
    "        \n",
    "    for i_pattern in range(net['p']['patts'].size):\n",
    "        patt = net['p']['patts'][i_pattern]\n",
    "        x = np.zeros((net['p']['N'],1))\n",
    "        for n in range(recallTestLength + net['p']['washoutLength']):\n",
    "            u = patt.take(n, mode='wrap', axis=0)\n",
    "            xOld = x\n",
    "            Wtarget = (net['Wstar'].dot(x)) + vstack((net['Win'].dot(u)))\n",
    "            x = ((1.0-net['p']['LR']) * xOld) + (net['p']['LR'] * tanh(Wtarget + net['Wbias']))\n",
    "            if (n > net['p']['washoutLength']):\n",
    "                pat_CTestPL[:,n-net['p']['washoutLength'] ] = u\n",
    "                \n",
    "                for i_ev in range(net['p']['patts'].size):\n",
    "                    C = patternCs[i_ev][0,0]\n",
    "                    C2 = patternCsNeg[i_ev]\n",
    "                    cx = x.T.dot(C.dot(x))\n",
    "                    cx2 = x.T.dot(C2.dot(x))\n",
    "                    cx_CTestPL[i_ev,n-net['p']['washoutLength']] = cx + cx2\n",
    "                cxNone = x.T.dot(CNone.dot(x))\n",
    "                cx_CTestPL[-1,n-net['p']['washoutLength']] = cxNone\n",
    "                    \n",
    "\n",
    "        ax = subplot(net['p']['patts'].size * 2, 2, i_pattern*2 + 1)\n",
    "#         ax.set_title(\"Sample \" + str(suboff/2) + \", pattern: \" + str(i_pattern) )\n",
    "#         plot([p['patts'][i_pattern](x) for x in arange(recallTestLength)])\n",
    "        plot(pat_CTestPL.T)\n",
    "        ax = subplot(net['p']['patts'].size * 2, 2, i_pattern*2 + 2)\n",
    "#         for i_plot in range(net['p']['patts'].size):\n",
    "#             plot(cx_CTestPL[i_plot,1:].T, label=i_plot, alpha=0.8)\n",
    "            \n",
    "        data = cx_CTestPL[0,1:].T * 3 - cx_CTestPL[1,1:].T - cx_CTestPL[2,1:].T - cx_CTestPL[3,1:].T\n",
    "        plot(data, label=0, alpha=0.8)\n",
    "        data = cx_CTestPL[1,1:].T * 3 - cx_CTestPL[0,1:].T - cx_CTestPL[2,1:].T - cx_CTestPL[3,1:].T\n",
    "        plot(data, label=1, alpha=0.8)\n",
    "        data = cx_CTestPL[2,1:].T * 3 - cx_CTestPL[0,1:].T - cx_CTestPL[1,1:].T - cx_CTestPL[3,1:].T\n",
    "        plot(data, label=2, alpha=0.8)\n",
    "        data = cx_CTestPL[3,1:].T * 3 - cx_CTestPL[0,1:].T - cx_CTestPL[1,1:].T - cx_CTestPL[2,1:].T\n",
    "        plot(data, label=3, alpha=0.8)\n",
    "\n",
    "            \n",
    "        #plot(cx_CTestPL[-1,1:].T, label=\"None\", alpha=0.8)\n",
    "        ax.legend()\n",
    "        classificationScore = np.sum(cx_CTestPL[i_pattern] ==  np.max(cx_CTestPL, axis=0)) / cx_CTestPL[0].size\n",
    "        otherResponses = cx_CTestPL[[x for x in arange(net['p']['patts'].size) if x != i_pattern]]\n",
    "        otherResponsesRange = dist.euclidean(np.max(otherResponses, axis=0),np.min(otherResponses, axis=0))\n",
    "        separation = dist.euclidean(cx_CTestPL[i_pattern],np.max(otherResponses, axis=0)) / otherResponsesRange\n",
    "        print(\"Pattern \", str(i_pattern), \" classification score: \", classificationScore, \", separation: \", separation)\n",
    "        #testing\n",
    "\n",
    "    return locals()\n",
    "\n",
    "def getAccuracyConceptorPatterns(net, cNet, recallTestLength):\n",
    "    patternCsNeg = np.zeros(len(apertures), dtype=np.object)\n",
    "\n",
    "    for i_c in arange(net['p']['patts'].size):\n",
    "        idxs = np.delete(arange(net['p']['patts'].size), i_c)\n",
    "        Cneg = conceptorOr(patternCs[idxs[0]][0,0], patternCs[idxs[1]][0,0])\n",
    "        for i_idx in idxs[2:]:\n",
    "            Cneg = conceptorOr(Cneg, patternCs[i_idx][0,0])\n",
    "        Cneg = 1.0 - Cneg\n",
    "        patternCsNeg[i_c] = Cneg\n",
    "\n",
    "#     x_CTestPL = np.zeros((3, recallTestLength, p['patts'].size))\n",
    "#     p_CTestPL = np.zeros((1, recallTestLength, p['patts'].size))\n",
    "    cx_CTestPL = np.zeros((net['p']['patts'].size+1,recallTestLength))\n",
    "    pat_CTestPL = np.zeros((net['p']['Nin'],recallTestLength))\n",
    "    \n",
    "    CNone = conceptorOr(patternCs[0][0,0], patternCs[1][0,0])\n",
    "    for i_idx in arange(net['p']['patts'].size)[2:]:\n",
    "        CNone = conceptorOr(CNone, patternCs[i_idx][0,0])\n",
    "    CNone = 1.0 - CNone\n",
    "    \n",
    "    classificationScores = np.zeros( net['p']['patts'].size )\n",
    "    separations = np.zeros( net['p']['patts'].size )\n",
    "    \n",
    "    for i_pattern in range(net['p']['patts'].size):\n",
    "        patt = net['p']['patts'][i_pattern]\n",
    "        x = np.zeros((net['p']['N'],1))\n",
    "        for n in range(recallTestLength + net['p']['washoutLength']):\n",
    "            u = patt.take(n, mode='wrap', axis=0)\n",
    "            xOld = x\n",
    "            Wtarget = (net['Wstar'].dot(x)) + vstack((net['Win'].dot(u)))\n",
    "            x = ((1.0-net['p']['LR']) * xOld) + (net['p']['LR'] * tanh(Wtarget + net['Wbias']))\n",
    "            if (n > net['p']['washoutLength']):\n",
    "                pat_CTestPL[:,n-net['p']['washoutLength'] ] = u\n",
    "                \n",
    "                for i_ev in range(net['p']['patts'].size):\n",
    "                    C = patternCs[i_ev][0,0]\n",
    "                    C2 = patternCsNeg[i_ev]\n",
    "                    cx = x.T.dot(C.dot(x))\n",
    "                    cx2 = x.T.dot(C2.dot(x))\n",
    "                    cx_CTestPL[i_ev,n-net['p']['washoutLength']] = cx + cx2\n",
    "                cxNone = x.T.dot(CNone.dot(x))\n",
    "                cx_CTestPL[-1,n-net['p']['washoutLength']] = cxNone\n",
    "                    \n",
    "\n",
    "        classificationScores[i_pattern] = np.sum(cx_CTestPL[i_pattern] ==  np.max(cx_CTestPL, axis=0)) / cx_CTestPL[0].size\n",
    "        otherResponses = cx_CTestPL[[x for x in arange(net['p']['patts'].size) if x != i_pattern]]\n",
    "        otherResponsesRange = dist.euclidean(np.max(otherResponses, axis=0),np.min(otherResponses, axis=0))\n",
    "        separations[i_pattern] = dist.euclidean(cx_CTestPL[i_pattern],np.max(otherResponses, axis=0)) / otherResponsesRange\n",
    "        print(\"Pattern \", str(i_pattern), \" classification score: \", classificationScores[i_pattern], \", separation: \", separations[i_pattern])\n",
    "\n",
    "    return locals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#runtime\n",
    "\n",
    "def generateClassificationConceptors(net, cNet):\n",
    "    #calc negative evidence\n",
    "    def conceptorOr(C,B):\n",
    "        I = np.eye(C.shape[0])\n",
    "        return linalg.inv(I + linalg.inv(C.dot(linalg.inv(1.0-C)) + B.dot(linalg.inv(1.0-B))))\n",
    "    patternCsNeg = np.zeros(len(apertures), dtype=np.object)\n",
    "\n",
    "    for i_c in arange(net['p']['patts'].size):\n",
    "        idxs = np.delete(arange(net['p']['patts'].size), i_c)\n",
    "        Cneg = conceptorOr(patternCs[idxs[0]][0,0], patternCs[idxs[1]][0,0])\n",
    "        for i_idx in idxs[2:]:\n",
    "            Cneg = conceptorOr(Cneg, patternCs[i_idx][0,0])\n",
    "        Cneg = 1.0 - Cneg\n",
    "        patternCsNeg[i_c] = Cneg\n",
    "\n",
    "    CNone = conceptorOr(patternCs[0][0,0], patternCs[1][0,0])\n",
    "    for i_idx in arange(net['p']['patts'].size)[2:]:\n",
    "        CNone = conceptorOr(CNone, patternCs[i_idx][0,0])\n",
    "    CNone = 1.0 - CNone\n",
    "    \n",
    "    return {'negatives':patternCsNeg, 'none':CNone}\n",
    "\n",
    "def iterate(net, Cs, classifierCs, u):\n",
    "    result = np.zeros(net['p']['patts'].size+1)\n",
    "    net['xOld'] = net['x']\n",
    "    Wtarget = (net['Wstar'].dot(net['x'])) + vstack((net['Win'].dot(u)))\n",
    "#     print( Wtarget.shape )\n",
    "    net['x'] = ((1.0-net['p']['LR']) * net['xOld']) + (net['p']['LR'] * tanh(Wtarget + net['Wbias']))\n",
    "    for i_ev in range(net['p']['patts'].size):\n",
    "        C = Cs[i_ev][0,0]\n",
    "        C2 = classifierCs['negatives'][i_ev]\n",
    "        cx = net['x'].T.dot(C.dot(net['x']))\n",
    "        cx2 = net['x'].T.dot(C2.dot(net['x']))\n",
    "        result[i_ev] = cx + cx2\n",
    "#         result[i_ev] = cx\n",
    "    cxNone = net['x'].T.dot(classifierCs['none'].dot(net['x']))\n",
    "#     net['xGest1'] = Cs[0][0,0].dot(net['x'])\n",
    "    result[-1] = cxNone\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# net = makeClassifierNetwork(params)\n",
    "# print(\"Made classifier network\")\n",
    "# cellbell.ding()\n",
    "\n",
    "# patternCs = calculate_apertures_and_conceptors()\n",
    "# print(\"Calculated apertures and conceptors\")\n",
    "# cellbell.ding()\n",
    "\n",
    "# ## before runtime\n",
    "# net['x'] = np.zeros((net['p']['N'],1))\n",
    "# classifierConceptors = generateClassificationConceptors(net, patternCs)\n",
    "# print(\"Generated classifier conceptors\")\n",
    "# cellbell.ding()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "def loadObject(filename):\n",
    "    with open(filename, \"rb\") as input_file:\n",
    "        restored = pickle.load(input_file)\n",
    "    return restored\n",
    "\n",
    "gestures = loadObject( \"patterns_chrysalis_1515598716.53275.pickled\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the functions for receiving and sending osc\n",
    "%run ../python/oscserver.py\n",
    "\n",
    "def onTrainModel( indices ):\n",
    "    global params, net, patternCs, apertures\n",
    "    save_gestures_to_file()\n",
    "    print( \"training model with gestures\", indices )\n",
    "    params['patts'] = gestures[ indices ]\n",
    "    oscserver.send_value( \"/model/trained\", 0 )\n",
    "    \n",
    "    net = makeClassifierNetwork(params)\n",
    "    print(\"Made classifier network\")\n",
    "    cellbell.ding()\n",
    "    oscserver.send_value( \"/model/trained\", 1 )\n",
    "    \n",
    "#     figsize(20,10)\n",
    "#     plot(net['allTrainxArgs'].T[:])\n",
    "#     cellbell.ding()\n",
    "\n",
    "    apertures = calculate_apertures()\n",
    "    patternCs = calculate_conceptors(apertures)\n",
    "    print(\"Calculated apertures and conceptors\")\n",
    "    cellbell.ding()\n",
    "    oscserver.send_value( \"/model/trained\", 2 )\n",
    "        \n",
    "    quality = getAccuracyConceptorPatterns(net, patternCs, 100)\n",
    "    oscserver.send_array( \"/model/separation\", quality['separations'] )\n",
    "    oscserver.send_array( \"/model/classificationScore\", quality['classificationScores'] )\n",
    "    cellbell.ding()\n",
    "    \n",
    "    oscserver.send_value( \"/model/trained\", 3 )\n",
    "    return True\n",
    "\n",
    "def onStartModel():\n",
    "    global classifierConceptors, modelIsTrained\n",
    "    ## before runtime\n",
    "    net['x'] = np.zeros((net['p']['N'],1))\n",
    "    classifierConceptors = generateClassificationConceptors(net, patternCs)\n",
    "    print(\"Generated classifier conceptors\")\n",
    "    modelIsTrained = True\n",
    "    cellbell.ding()\n",
    "    oscserver.send_value( \"/model/started\", 1 )\n",
    "    return True\n",
    "\n",
    "\n",
    "def onRecordOn( ind ):\n",
    "    global recIndex, isRecording, newGesture, modelIsTrained\n",
    "    modelIsTrained = False\n",
    "    recIndex = ind\n",
    "    isRecording = True\n",
    "    newGesture = np.zeros(0)\n",
    "    print( \"started recording\", recIndex )\n",
    "    return True\n",
    "\n",
    "def onRecordOff():\n",
    "    global isRecording, newGesture, gestures\n",
    "    isRecording = False\n",
    "    newGesture = newGesture.reshape( int( newGesture.shape[0]/len(inputValues)),len(inputValues))\n",
    "    gestures[ recIndex ] = newGesture\n",
    "    print( \"stopped recording\", recIndex, shape( newGesture ) )\n",
    "    return True\n",
    "\n",
    "def onAccelero(args):\n",
    "    global inputValues, newGesture\n",
    "#     print( args )\n",
    "    inputValues = args\n",
    "    if isRecording:\n",
    "        newGesture = np.append( newGesture, inputValues )\n",
    "    if modelIsTrained:\n",
    "        output = iterate(net, patternCs, classifierConceptors, inputValues)\n",
    "        oscserver.send_array( \"/output\", output )\n",
    "    return True\n",
    "\n",
    "def onExit():\n",
    "    print( \"exiting\" )\n",
    "    global keepRunning\n",
    "    keepRunning = False\n",
    "    oscserver.free()\n",
    "    return True\n",
    "\n",
    "oscserver = makeOSCServer(57120, 57402, onExit)\n",
    "oscserver.onAccelero = onAccelero\n",
    "oscserver.onRecordOff = onRecordOff\n",
    "oscserver.onRecordOn = onRecordOn\n",
    "oscserver.onTrainModel = onTrainModel\n",
    "oscserver.onStartModel = onStartModel\n",
    "\n",
    "oscserver.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
